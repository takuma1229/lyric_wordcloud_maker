{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_words_in_doc(text, include_pos, stopwords):\n",
    "  nlp = spacy.load(\"ja_ginza\")\n",
    "  split_number = len(text) // 15000 + 1\n",
    "  words = []\n",
    "  for i in range(1, split_number):\n",
    "    text = text[15000*(split_number-1):min((15000*split_number), len(text))]\n",
    "    doc = nlp(text)\n",
    "    df = pd.DataFrame({\n",
    "    'text': token.text,\n",
    "    'lemma_': token.lemma_,\n",
    "    'pos_': token.pos_,\n",
    "    'tag_': token.tag_,\n",
    "    'dep_': token.dep_,\n",
    "    'children': list(token.children)\n",
    "    } for token in doc)\n",
    "    from collections import Counter\n",
    "    counter = Counter(token.lemma_ for token in doc\n",
    "                  if token.pos_ in include_pos and token.lemma_ not in stopwords)\n",
    "    words = words.exted([token.lemma_ for token in doc\n",
    "         if token.pos_ in include_pos and token.lemma_ not in stopwords])\n",
    "    return words\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "name": "python3910jvsc74a57bd0ac2eaa0ea0ebeafcc7822e65e46aa9d4f966f30b695406963e145ea4a91cd4fc"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "metadata": {
   "interpreter": {
    "hash": "ac2eaa0ea0ebeafcc7822e65e46aa9d4f966f30b695406963e145ea4a91cd4fc"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}